{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "import rp2\n",
    "from rp2 import hagai_2018, create_gene_symbol_map\n",
    "from rp2.paths import get_txburst_results_csv_path\n",
    "\n",
    "rp2.check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_species = \"mouse\"\n",
    "analysis_counts = \"median\"\n",
    "analysis_treatments = [\"unst\", \"lps\"]\n",
    "analysis_time_points = [\"0\", \"2\", \"4\", \"6\"]\n",
    "\n",
    "min_conditions = 6\n",
    "\n",
    "index_columns = [\"replicate\", \"treatment\", \"time_point\"]\n",
    "all_index_columns = [\"gene\"] + index_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_symbol_map = create_gene_symbol_map(analysis_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_info_df = pd.read_csv(get_txburst_results_csv_path(analysis_species, index_columns, count_type=analysis_counts))\n",
    "condition_info_df.replicate = condition_info_df.replicate.astype(str)\n",
    "\n",
    "condition_info_df = condition_info_df.loc[condition_info_df.treatment.isin(analysis_treatments)]\n",
    "condition_info_df = condition_info_df.loc[condition_info_df.time_point.isin(analysis_time_points)]\n",
    "print(f\"{len(condition_info_df):,} conditions with {condition_info_df.gene.nunique():,} genes\")\n",
    "\n",
    "condition_info_df[\"valid\"] = condition_info_df.bs_point.notna() & condition_info_df.bf_point.notna()\n",
    "condition_info_df = condition_info_df.loc[condition_info_df.valid]\n",
    "\n",
    "valid_counts = condition_info_df.groupby(\"gene\").valid.count()\n",
    "valid_gene_ids = valid_counts.index[valid_counts >= min_conditions]\n",
    "print(f\"Reduced to {len(valid_gene_ids):,} genes with {min_conditions} or more conditions\")\n",
    "\n",
    "condition_info_df = condition_info_df.loc[condition_info_df.gene.isin(valid_gene_ids)]\n",
    "print(f\"{len(condition_info_df):,} conditions with {condition_info_df.gene.nunique():,} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_count_stats():\n",
    "    counts_adata = hagai_2018.load_counts(analysis_species, scaling=analysis_counts)\n",
    "    counts_adata = counts_adata[counts_adata.obs.treatment.isin(analysis_treatments)]\n",
    "    counts_adata = counts_adata.copy()\n",
    "    return hagai_2018.calculate_counts_condition_stats(counts_adata, group_columns=index_columns)\n",
    "\n",
    "\n",
    "condition_info_df = condition_info_df.set_index(all_index_columns).join(\n",
    "    calculate_count_stats().set_index(all_index_columns),\n",
    "    how=\"left\",\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regression(df, x_var, y_var, Regressor=HuberRegressor, include_outliers=False):\n",
    "    rx, ry = df.loc[:, [x_var, y_var]].to_numpy().reshape(1, -1, 2).T\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        r = Regressor().fit(rx, ry)\n",
    "\n",
    "    results = {\n",
    "        \"slope\": r.coef_.item(),\n",
    "        \"intercept\": r.intercept_.item(),\n",
    "        \"r2\": r.score(rx, ry),\n",
    "    }\n",
    "    if include_outliers:\n",
    "        results[\"outliers\"] = r.outliers_\n",
    "        # results[\"r2_without_outliers\"] = r.score(rx[~r.outliers_], ry[~r.outliers_])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "condition_info_df[\"mv_outlier\"] = False\n",
    "mv_gene_info_df = pd.DataFrame()\n",
    "\n",
    "for gene_id, gene_df in condition_info_df.groupby(\"gene\"):\n",
    "    results = calculate_regression(gene_df, \"mean\", \"variance\", include_outliers=True)\n",
    "\n",
    "    outliers = results.pop(\"outliers\")\n",
    "    results[\"n_outliers\"] = np.count_nonzero(outliers)\n",
    "\n",
    "    mv_gene_info_df = mv_gene_info_df.append(pd.DataFrame(index=[gene_id], data=results))\n",
    "    condition_info_df.loc[gene_df.index, \"mv_outlier\"] = outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_function(x, a, b, c):\n",
    "    return (a * np.power(x, b)) + c\n",
    "\n",
    "\n",
    "def calculate_curve_fit(df, x_var, y_var):\n",
    "    x, y = df.loc[:, [x_var, y_var]].to_numpy().T\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            params, cov = curve_fit(\n",
    "                power_function,\n",
    "                x,\n",
    "                y,\n",
    "                p0=[1, 1, 0],\n",
    "            )\n",
    "    except:\n",
    "        params = [np.nan] * 3\n",
    "    return {\n",
    "        \"a\": params[0],\n",
    "        \"b\": params[1],\n",
    "        \"c\": params[2],\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_per_gene_info(df):\n",
    "    lr_dict = {\n",
    "        \"bf\": calculate_regression(df, \"mean\", \"bf_point\"),\n",
    "        \"bs\": calculate_regression(df, \"mean\", \"bs_point\"),\n",
    "    }\n",
    "\n",
    "    curve_dict = {\n",
    "        \"bf\": calculate_curve_fit(df, \"mean\", \"bf_point\"),\n",
    "        \"bs\": calculate_curve_fit(df, \"mean\", \"bs_point\"),\n",
    "    }\n",
    "\n",
    "    results_dict = {\n",
    "        \"n_conditions\": len(df),\n",
    "    }\n",
    "    for lr_n, lr_v in lr_dict.items():\n",
    "        for n, v in lr_v.items():\n",
    "            results_dict[f\"{lr_n}_{n}\"] = v\n",
    "    for curve_n, curve_v in curve_dict.items():\n",
    "        for n, v in curve_v.items():\n",
    "            results_dict[f\"{curve_n}_pf_{n}\"] = v\n",
    "\n",
    "    return pd.Series(results_dict)\n",
    "\n",
    "\n",
    "gene_info_df = condition_info_df.groupby(\"gene\").apply(calculate_per_gene_info).join(\n",
    "    mv_gene_info_df.rename(columns={n: f\"mv_{n}\" for n in mv_gene_info_df.columns}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    x=\"bs_r2\",\n",
    "    y=\"bf_r2\",\n",
    "    data=gene_info_df,\n",
    ")\n",
    "plt.plot((-0.5, 1), (-0.5, 1), \"-\")\n",
    "plt.axvline(x=0, ls=\":\")\n",
    "plt.axhline(y=0, ls=\":\")\n",
    "ax.set_aspect(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relationship_scatter(ax, condition_info, lr_info, y_var_prefix, y_var=None):\n",
    "    y_var = y_var or f\"{y_var_prefix}_point\"\n",
    "    x_range = np.asarray((0, condition_info[\"mean\"].max()))\n",
    "\n",
    "    ax.scatter(\n",
    "        condition_info.loc[~condition_info.mv_outlier, \"mean\"],\n",
    "        condition_info.loc[~condition_info.mv_outlier, y_var],\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        condition_info.loc[condition_info.mv_outlier, \"mean\"],\n",
    "        condition_info.loc[condition_info.mv_outlier, y_var],\n",
    "        marker=\"x\",\n",
    "        label=\"mv outlier\",\n",
    "    )\n",
    "    ax.plot(x_range, (x_range * lr_info[f\"{y_var_prefix}_slope\"]) + lr_row[f\"{y_var_prefix}_intercept\"])\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xlabel(\"mean\")\n",
    "    ax.set_ylabel(y_var)\n",
    "\n",
    "    r2 = lr_info[f\"{y_var_prefix}_r2\"]\n",
    "    ax.set_title(f\"$R^2=${r2:.2f}\")\n",
    "\n",
    "\n",
    "def plot_relationship_curve(ax, condition_info, lr_info, y_var_prefix):\n",
    "    a, b, c = [lr_info[f\"{y_var_prefix}_pf_{coef}\"] for coef in [\"a\", \"b\", \"c\"]]\n",
    "    if a is np.nan: return\n",
    "\n",
    "    x = np.linspace(np.finfo(np.float).eps, condition_info[\"mean\"].max())\n",
    "    y = power_function(x, a, b, c)\n",
    "\n",
    "    ax.plot(x, y, \"--\")\n",
    "\n",
    "\n",
    "lr_to_plot = gene_info_df.sort_values(by=\"bf_r2\", ascending=False)\n",
    "for idx, (gene_id, lr_row) in enumerate(lr_to_plot.iterrows(), start=1):\n",
    "    print(f\"{idx}. {gene_symbol_map.lookup(gene_id)}\")\n",
    "    display(lr_row.to_frame().T)\n",
    "\n",
    "    condition_info_subset = condition_info_df.loc[condition_info_df.gene == gene_id]\n",
    "\n",
    "    _, axes = plt.subplots(ncols=3, figsize=(12, 4), sharex=True)\n",
    "    for prefix, ax in zip((\"bf\", \"bs\"), axes[:2]):\n",
    "        plot_relationship_scatter(ax, condition_info_subset, lr_row, prefix)\n",
    "        plot_relationship_curve(ax, condition_info_subset, lr_row, prefix)\n",
    "    plot_relationship_scatter(axes[2], condition_info_subset, lr_row, \"mv\", y_var=\"variance\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.ipynb.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
