{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rp2 import create_folder, working_directory, hagai_2018, notebooks\n",
    "from rp2.paths import get_scripts_path, get_txburst_results_csv_path, get_data_path\n",
    "\n",
    "nb_env, data_proc_nb = notebooks.initialise_environment(\n",
    "    \"Burst_Model_Fitting\",\n",
    "    dependencies=[\"Data_Processing\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "study_species = \"mouse\"\n",
    "\n",
    "analysis_gene_ids = data_proc_nb.access_path(f\"all_analysis_genes-species={study_species}.txt\").read_text().split(\"\\n\")\n",
    "print(f\"Wish to fit burst parameters for {len(analysis_gene_ids):,} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mouse_orthologues():\n",
    "    df = pd.read_table(\n",
    "        get_data_path(\"BioMart\", \"mouse_orthologues.tsv\"),\n",
    "        names=[\"mouse_gene\", \"pig_gene\", \"rabbit_gene\", \"rat_gene\"],\n",
    "        index_col=0,\n",
    "    )\n",
    "    df = df.dropna(axis=0)\n",
    "    df = df.loc[~df.index.duplicated(False)]\n",
    "    return df\n",
    "\n",
    "\n",
    "orthologues_df = load_mouse_orthologues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BurstParameterSet:\n",
    "    def __init__(self, gene_list, index_columns, count_type, species=study_species):\n",
    "        self.species = species\n",
    "        self.gene_list = gene_list\n",
    "        self.index_columns = index_columns\n",
    "        self.count_type = count_type\n",
    "\n",
    "    def load_counts(self):\n",
    "        counts_adata = hagai_2018.load_counts(self.species, scaling=self.count_type)\n",
    "        counts_adata = counts_adata[:, self.gene_list].copy()\n",
    "        return counts_adata\n",
    "\n",
    "    @property\n",
    "    def counts_key(self):\n",
    "        return self.species + \"-\" + self.count_type\n",
    "\n",
    "    @property\n",
    "    def results_path(self):\n",
    "        return get_txburst_results_csv_path(self.species, self.index_columns, self.count_type)\n",
    "\n",
    "\n",
    "txburst_param_sets = []\n",
    "\n",
    "for count_type in [\"umi\", \"median\"]:\n",
    "    txburst_param_sets.append(BurstParameterSet(\n",
    "        analysis_gene_ids,\n",
    "        [\"replicate\", \"treatment\", \"time_point\"],\n",
    "        count_type,\n",
    "    ))\n",
    "\n",
    "for species in [\"pig\", \"rabbit\", \"rat\"]:\n",
    "    txburst_param_sets.append(BurstParameterSet(\n",
    "        orthologues_df.loc[orthologues_df.index.isin(analysis_gene_ids), f\"{species}_gene\"],\n",
    "        [\"replicate\", \"treatment\", \"time_point\"],\n",
    "        \"median\",\n",
    "        species=species,\n",
    "    ))\n",
    "\n",
    "txburst_param_sets.append(BurstParameterSet(\n",
    "    analysis_gene_ids,\n",
    "    [\"treatment\", \"time_point\"],\n",
    "    \"umi\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_counts(counts_adata, output_path):\n",
    "    csv_path = output_path.joinpath(\"counts.csv\")\n",
    "    counts_adata.to_df().T.to_csv(csv_path, index_label=\"gene\")\n",
    "\n",
    "\n",
    "def run_txburst_fitting(count_files_path, execute_commands=True):\n",
    "    txburst_script_path = get_scripts_path(\"txburst\")\n",
    "\n",
    "    with working_directory(count_files_path):\n",
    "        for full_csv_file_path in count_files_path.glob(\"*.csv\"):\n",
    "            csv_file_path = full_csv_file_path.name\n",
    "            ml_file_path = Path(full_csv_file_path.stem + \"_ML.pkl\")\n",
    "            pl_file_path = Path(full_csv_file_path.stem + \"_PL.pkl\")\n",
    "\n",
    "            txburst_ml_script_path = txburst_script_path.joinpath(\"txburstML.py\")\n",
    "            txburst_pl_script_path = txburst_script_path.joinpath(\"txburstPL.py\")\n",
    "\n",
    "            common_options = \"--njobs 4\"\n",
    "            commands = []\n",
    "            if not pl_file_path.exists():\n",
    "                commands.append(f\"{txburst_ml_script_path} {common_options} {csv_file_path}\")\n",
    "            if not ml_file_path.exists():\n",
    "                commands.append(f\"{txburst_pl_script_path} {common_options} --file {csv_file_path} --MLFile {ml_file_path}\")\n",
    "\n",
    "            for cmd in commands:\n",
    "                print(\"Executing:\", cmd)\n",
    "                if execute_commands:\n",
    "                    %run {cmd}\n",
    "\n",
    "\n",
    "def load_txburst_pkl_file(pkl_path):\n",
    "    return pd.read_pickle(pkl_path).reset_index(\"gene\")\n",
    "    \n",
    "\n",
    "def explode_txburst_columns(df, column_id, new_columns):\n",
    "    if df.empty:\n",
    "        for c in new_columns:\n",
    "            df[c] = None\n",
    "        return\n",
    "\n",
    "    df[new_columns] = pd.DataFrame(df.loc[:, column_id].to_list())\n",
    "    df.drop(columns=column_id, inplace=True)\n",
    "\n",
    "\n",
    "def collate_txburst_results(pkl_files_path):\n",
    "    ml_df, pl_df = [load_txburst_pkl_file(pkl_files_path.joinpath(f\"counts_{suffix}.pkl\"))\n",
    "                    for suffix in [\"ML\", \"PL\"]]\n",
    "\n",
    "    ml_df.rename(columns={1: \"keep\"}, inplace=True)\n",
    "\n",
    "    for df in [ml_df, pl_df]:\n",
    "        explode_txburst_columns(df, 0, [\"k_on\", \"k_off\", \"k_syn\"])\n",
    "\n",
    "    explode_txburst_columns(pl_df, 1, [\"bf_point\", \"bf_lower\", \"bf_upper\"])\n",
    "    explode_txburst_columns(pl_df, 2, [\"bs_point\", \"bs_lower\", \"bs_upper\"])\n",
    "\n",
    "    ml_df = ml_df.set_index(\"gene\")\n",
    "    pl_df = pl_df.set_index(\"gene\")\n",
    "\n",
    "    txburst_df = pl_df.join(ml_df.keep, how=\"outer\")\n",
    "    txburst_df.update(ml_df)\n",
    "    txburst_df = txburst_df.reset_index()\n",
    "\n",
    "    return txburst_df\n",
    "\n",
    "\n",
    "def get_genes_with_results(txburst_df, index_values):\n",
    "    for column, value in index_values:\n",
    "        txburst_df = txburst_df.loc[txburst_df[column] == value]\n",
    "    return txburst_df.gene\n",
    "\n",
    "\n",
    "counts_adata_map = {}\n",
    "\n",
    "for txburst_param_set in txburst_param_sets:\n",
    "    print(f\"Processing {txburst_param_set.results_path}\")\n",
    "\n",
    "    if txburst_param_set.counts_key in counts_adata_map:\n",
    "        counts_adata = counts_adata_map[txburst_param_set.counts_key]\n",
    "    else:\n",
    "        print(f'  Loading \"{txburst_param_set.counts_key}\" counts')\n",
    "        counts_adata = txburst_param_set.load_counts()\n",
    "        counts_adata_map[txburst_param_set.counts_key] = counts_adata\n",
    "\n",
    "    if txburst_param_set.results_path.exists():\n",
    "        results_df = pd.read_csv(txburst_param_set.results_path, float_precision=\"round_trip\")\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=[\"gene\", \"replicate\", \"treatment\", \"time_point\", \"k_on\", \"k_off\", \"k_syn\", \"bf_point\", \"bf_lower\", \"bf_upper\", \"bs_point\", \"bs_lower\", \"bs_upper\", \"keep\"])\n",
    "\n",
    "    for index_columns in txburst_param_set.index_columns:\n",
    "        results_df[index_columns] = results_df[index_columns].astype(str)\n",
    "\n",
    "    sort_columns = [c for c in [\"gene\", \"replicate\", \"time_point\", \"treatment\"] if c in results_df.columns]\n",
    "\n",
    "    full_gene_set = set(txburst_param_set.gene_list)\n",
    "    print(f\"  {len(full_gene_set):,} genes per condition\")\n",
    "\n",
    "    for index_values, index_df in counts_adata.obs.groupby(txburst_param_set.index_columns):\n",
    "        genes_with_results = get_genes_with_results(results_df, zip(txburst_param_set.index_columns, index_values))\n",
    "        required_genes = list(full_gene_set.difference(genes_with_results))\n",
    "        print(f\"  {len(required_genes):,} genes required for condition {index_values}\")\n",
    "        if len(required_genes) == 0:\n",
    "            continue\n",
    "\n",
    "        tmp_folder_name = \"-\".join(f\"{n}={v}\" for n, v in zip(txburst_param_set.index_columns, index_values))\n",
    "        tmp_path = nb_env.get_intermediate_path(\"txburst\", txburst_param_set.results_path.stem, tmp_folder_name)\n",
    "        create_folder(tmp_path, create_clean=True)\n",
    "\n",
    "        counts_subset = counts_adata[index_df.index, required_genes]\n",
    "        write_counts(counts_subset, tmp_path)\n",
    "\n",
    "        run_txburst_fitting(tmp_path)\n",
    "\n",
    "        txburst_df = collate_txburst_results(tmp_path)\n",
    "\n",
    "        for loc, (column, value) in enumerate(zip(txburst_param_set.index_columns, index_values), start=1):\n",
    "            txburst_df.insert(loc, column, value)\n",
    "\n",
    "        results_df = results_df.append(txburst_df)\n",
    "        results_df = results_df.sort_values(by=sort_columns)\n",
    "        results_df.to_csv(txburst_param_set.results_path, index=False)\n",
    "\n",
    "    n_results = len(results_df)\n",
    "    n_keep = np.count_nonzero(results_df.keep)\n",
    "    print(f\"  Summary:\")\n",
    "    print(f\"    {n_results} results\")\n",
    "    print(f\"    {n_keep} ({(n_keep / n_results) * 100:.0f}%) flagged to keep\")\n",
    "\n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.ipynb.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
