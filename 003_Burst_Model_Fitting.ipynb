{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from rp2 import create_folder, working_directory, create_gene_symbol_map, hagai_2018\n",
    "from rp2.paths import get_output_path, get_scripts_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_species = \"mouse\"\n",
    "\n",
    "umi_count_ad = hagai_2018.load_umi_count(study_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_map = create_gene_symbol_map(study_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsive_phagocyte_genes = hagai_2018.load_lps_responsive_genes()\n",
    "print(f\"{len(responsive_phagocyte_genes):,} responsive phagocyte genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def write_umi_subsets(output_path, obs_groups):\n",
    "    create_folder(output_path, create_clean=True)\n",
    "\n",
    "    for group_values, df in umi_count_ad.obs.groupby(obs_groups):\n",
    "        suffix = \"_\".join(group_values)\n",
    "        csv_path = output_path.joinpath(f\"{study_species}_umi_{suffix}.csv\")\n",
    "        print(\"Writing:\", csv_path.name)\n",
    "        subset_ad = umi_count_ad[df.index.values, genes]\n",
    "        subset_ad.to_df().T.to_csv(csv_path, index_label=\"gene\")\n",
    "\n",
    "    output_path.joinpath(\"groups.txt\").write_text(\"\\t\".join(obs_groups))\n",
    "\n",
    "\n",
    "gene_sets = {\n",
    "    f\"{study_species}_responsive_genes\": responsive_phagocyte_genes,\n",
    "}\n",
    "\n",
    "txburst_output_path = get_output_path(\"txburst\")\n",
    "create_folder(txburst_output_path)\n",
    "\n",
    "for gene_set_name, genes in gene_sets.items():\n",
    "    all_sets = (\n",
    "        (gene_set_name, [\"replicate\", \"treatment\", \"time_point\"]),\n",
    "        (gene_set_name + \"_combined_replicates\", [\"treatment\", \"time_point\"]),\n",
    "    )\n",
    "\n",
    "    for set_name, umi_groups in all_sets:\n",
    "        gene_set_output_path = txburst_output_path.joinpath(set_name)\n",
    "        if gene_set_output_path.exists():\n",
    "            print(\"Skipping:\", set_name)\n",
    "            continue\n",
    "\n",
    "        write_umi_subsets(gene_set_output_path, umi_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_txburst_fitting(umi_files_path, execute_commands=True):\n",
    "    txburst_script_path = get_scripts_path(\"txburst\")\n",
    "\n",
    "    with working_directory(umi_files_path):\n",
    "        for full_csv_file_path in umi_files_path.glob(\"*.csv\"):\n",
    "            csv_file_path = full_csv_file_path.name\n",
    "            ml_file_path = Path(full_csv_file_path.stem + \"_ML.pkl\")\n",
    "            pl_file_path = Path(full_csv_file_path.stem + \"_PL.pkl\")\n",
    "\n",
    "            txburst_ml_script_path = txburst_script_path.joinpath(\"txburstML.py\")\n",
    "            txburst_pl_script_path = txburst_script_path.joinpath(\"txburstPL.py\")\n",
    "\n",
    "            commands = []\n",
    "            if not pl_file_path.exists():\n",
    "                commands.append(f\"{txburst_ml_script_path} --njobs 4 {csv_file_path}\")\n",
    "            if not ml_file_path.exists():\n",
    "                commands.append(f\"{txburst_pl_script_path} --njobs 4 --file {csv_file_path} --MLFile {ml_file_path}\")\n",
    "\n",
    "            for cmd in commands:\n",
    "                print(\"Executing:\", cmd)\n",
    "                if execute_commands:\n",
    "                    %run {cmd}\n",
    "\n",
    "\n",
    "def load_txburst_pkl_files(pkl_paths, condition_names):\n",
    "    df_list = []\n",
    "\n",
    "    for pkl_path in pkl_paths:\n",
    "        condition_values = pkl_path.stem[:-3].split(\"_\")[-len(condition_names):]\n",
    "        pkl_df = pd.read_pickle(pkl_path)\n",
    "\n",
    "        condition_df = pkl_df.reset_index(\"gene\")\n",
    "        for condition_name, condition_value in zip(condition_names, condition_values):\n",
    "            condition_df[condition_name] = condition_value\n",
    "\n",
    "        df_list.append(condition_df)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "def collate_txburst_results(pkl_files_path):\n",
    "    condition_groups = pkl_files_path.joinpath(\"groups.txt\").read_text().split(\"\\t\")\n",
    "\n",
    "    ml_df = load_txburst_pkl_files(pkl_files_path.glob(\"*_ML.pkl\"), condition_groups)\n",
    "    pl_df = load_txburst_pkl_files(pkl_files_path.glob(\"*_PL.pkl\"), condition_groups)\n",
    "\n",
    "    for df in [ml_df, pl_df]:\n",
    "        df[[\"k_on\", \"k_off\", \"k_syn\"]] = pd.DataFrame(df.loc[:, 0].to_list())\n",
    "\n",
    "    ml_df.rename(columns={1: \"keep\"}, inplace=True)\n",
    "    ml_df.drop(columns=[0], inplace=True)\n",
    "\n",
    "    pl_df[[\"bf_point\", \"bf_lower\", \"bf_upper\"]] = pd.DataFrame(pl_df.loc[:, 1].to_list())\n",
    "    pl_df[[\"bs_point\", \"bs_lower\", \"bs_upper\"]] = pd.DataFrame(pl_df.loc[:, 2].to_list())\n",
    "    pl_df.drop(columns=[0, 1, 2], inplace=True)\n",
    "\n",
    "    index_columns = [\"gene\"] + condition_groups\n",
    "    ml_df = ml_df.set_index(index_columns)\n",
    "    pl_df = pl_df.set_index(index_columns)\n",
    "\n",
    "    txburst_df = pl_df.join(ml_df.keep, how=\"outer\")\n",
    "    txburst_df.update(ml_df)\n",
    "    txburst_df = txburst_df.reset_index()\n",
    "\n",
    "    sort_columns = [c for c in [\"gene\", \"replicate\", \"time_point\", \"treatment\"] if c in txburst_df.columns]\n",
    "    return txburst_df.sort_values(by=sort_columns)\n",
    "\n",
    "\n",
    "for sub_folder in filter(Path.is_dir, txburst_output_path.iterdir()):\n",
    "    collated_csv_path = sub_folder.with_suffix(\".csv\")\n",
    "    if collated_csv_path.exists():\n",
    "        print(\"Skipping:\", sub_folder.name)\n",
    "        txburst_df = pd.read_csv(collated_csv_path)\n",
    "    else:\n",
    "        run_txburst_fitting(sub_folder)\n",
    "        txburst_df = collate_txburst_results(sub_folder)\n",
    "        txburst_df.to_csv(collated_csv_path, index=False)\n",
    "\n",
    "    txburst_df = txburst_df.loc[txburst_df.keep]\n",
    "\n",
    "    display(symbol_map.added_to(txburst_df))\n",
    "\n",
    "    totals_df = txburst_df.gene.value_counts().sort_values(ascending=False).to_frame(\"n_conditions\")\n",
    "    totals_df = totals_df.sort_values(by=\"n_conditions\", ascending=False)\n",
    "    totals_df.index.name = \"gene\"\n",
    "    display(symbol_map.added_to(totals_df))\n",
    "    sns.countplot(\n",
    "        x=\"n_conditions\",\n",
    "        data=totals_df,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.ipynb.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
