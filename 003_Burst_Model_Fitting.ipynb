{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from rp2 import create_folder, working_directory, hagai_2018, notebooks\n",
    "from rp2.paths import get_scripts_path, get_txburst_results_csv_path\n",
    "\n",
    "nb_env, data_proc_nb = notebooks.initialise_environment(\n",
    "    \"Burst_Model_Fitting\",\n",
    "    dependencies=[\"Data_Processing\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_species = \"mouse\"\n",
    "\n",
    "full_gene_list = data_proc_nb.access_path(f\"all_analysis_genes-species={study_species}.txt\").read_text().split(\"\\n\")\n",
    "print(f\"Wish to fit burst parameters for {len(full_gene_list):,} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_counts_ad = hagai_2018.load_umi_counts_with_additional_annotation(study_species)\n",
    "umi_counts_ad = umi_counts_ad[:, full_gene_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BurstParameterSet = namedtuple(\"BurstParameterSet\", [\"gene_list\", \"index_columns\", \"results_path\"])\n",
    "\n",
    "txburst_param_sets = [\n",
    "    BurstParameterSet(\n",
    "        full_gene_list,\n",
    "        [\"replicate\", \"treatment\", \"time_point\"],\n",
    "        get_txburst_results_csv_path(study_species),\n",
    "    ),\n",
    "    BurstParameterSet(\n",
    "        full_gene_list,\n",
    "        [\"treatment\", \"time_point\"],\n",
    "        get_txburst_results_csv_path(study_species, combined_replicates=True),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_umi_counts(umi_counts, output_path):\n",
    "    csv_path = output_path.joinpath(\"umi_counts.csv\")\n",
    "    umi_counts.to_df().T.to_csv(csv_path, index_label=\"gene\")\n",
    "\n",
    "\n",
    "def run_txburst_fitting(umi_files_path, execute_commands=True):\n",
    "    txburst_script_path = get_scripts_path(\"txburst\")\n",
    "\n",
    "    with working_directory(umi_files_path):\n",
    "        for full_csv_file_path in umi_files_path.glob(\"*.csv\"):\n",
    "            csv_file_path = full_csv_file_path.name\n",
    "            ml_file_path = Path(full_csv_file_path.stem + \"_ML.pkl\")\n",
    "            pl_file_path = Path(full_csv_file_path.stem + \"_PL.pkl\")\n",
    "\n",
    "            txburst_ml_script_path = txburst_script_path.joinpath(\"txburstML.py\")\n",
    "            txburst_pl_script_path = txburst_script_path.joinpath(\"txburstPL.py\")\n",
    "\n",
    "            commands = []\n",
    "            if not pl_file_path.exists():\n",
    "                commands.append(f\"{txburst_ml_script_path} --njobs 4 {csv_file_path}\")\n",
    "            if not ml_file_path.exists():\n",
    "                commands.append(f\"{txburst_pl_script_path} --njobs 4 --file {csv_file_path} --MLFile {ml_file_path}\")\n",
    "\n",
    "            for cmd in commands:\n",
    "                print(\"Executing:\", cmd)\n",
    "                if execute_commands:\n",
    "                    %run {cmd}\n",
    "\n",
    "\n",
    "def load_txburst_pkl_file(pkl_path):\n",
    "    return pd.read_pickle(pkl_path).reset_index(\"gene\")\n",
    "    \n",
    "\n",
    "def explode_txburst_columns(df, column_id, new_columns):\n",
    "    if df.empty:\n",
    "        for c in new_columns:\n",
    "            df[c] = None\n",
    "        return\n",
    "\n",
    "    df[new_columns] = pd.DataFrame(df.loc[:, column_id].to_list())\n",
    "    df.drop(columns=column_id, inplace=True)\n",
    "\n",
    "\n",
    "def collate_txburst_results(pkl_files_path):\n",
    "    ml_df, pl_df = [load_txburst_pkl_file(pkl_files_path.joinpath(f\"umi_counts_{suffix}.pkl\"))\n",
    "                    for suffix in [\"ML\", \"PL\"]]\n",
    "\n",
    "    ml_df.rename(columns={1: \"keep\"}, inplace=True)\n",
    "\n",
    "    for df in [ml_df, pl_df]:\n",
    "        explode_txburst_columns(df, 0, [\"k_on\", \"k_off\", \"k_syn\"])\n",
    "\n",
    "    explode_txburst_columns(pl_df, 1, [\"bf_point\", \"bf_lower\", \"bf_upper\"])\n",
    "    explode_txburst_columns(pl_df, 2, [\"bs_point\", \"bs_lower\", \"bs_upper\"])\n",
    "\n",
    "    index_columns = [\"gene\"]\n",
    "    ml_df = ml_df.set_index(index_columns)\n",
    "    pl_df = pl_df.set_index(index_columns)\n",
    "\n",
    "    txburst_df = pl_df.join(ml_df.keep, how=\"outer\")\n",
    "    txburst_df.update(ml_df)\n",
    "    txburst_df = txburst_df.reset_index()\n",
    "\n",
    "    return txburst_df\n",
    "\n",
    "\n",
    "def get_genes_with_results(txburst_df, index_values):\n",
    "    for column, value in index_values:\n",
    "        txburst_df = txburst_df.loc[txburst_df[column] == value]\n",
    "    return txburst_df.gene\n",
    "\n",
    "\n",
    "\n",
    "for txburst_param_set in txburst_param_sets:\n",
    "    print(f\"Processing {txburst_param_set.results_path}\")\n",
    "\n",
    "    results_df = pd.read_csv(txburst_param_set.results_path, float_precision=\"round_trip\")\n",
    "    for index_column in txburst_param_set.index_columns:\n",
    "        results_df[index_column] = results_df[index_column].astype(str)\n",
    "\n",
    "    sort_columns = [c for c in [\"gene\", \"replicate\", \"time_point\", \"treatment\"] if c in results_df.columns]\n",
    "\n",
    "    full_gene_set = set(txburst_param_set.gene_list)\n",
    "    print(f\"  {len(full_gene_set):,} genes per condition\")\n",
    "\n",
    "    for index_values, index_df in umi_counts_ad.obs.groupby(txburst_param_set.index_columns):\n",
    "        genes_with_results = get_genes_with_results(results_df, zip(txburst_param_set.index_columns, index_values))\n",
    "        required_genes = list(full_gene_set.difference(genes_with_results))\n",
    "        print(f\"  {len(required_genes):,} genes required for condition {index_values}\")\n",
    "        if len(required_genes) == 0:\n",
    "            continue\n",
    "\n",
    "        tmp_folder_name = \"-\".join(f\"{n}={v}\" for n, v in zip(txburst_param_set.index_columns, index_values))\n",
    "        tmp_path = nb_env.get_intermediate_path(\"txburst\", txburst_param_set.results_path.stem, tmp_folder_name)\n",
    "        create_folder(tmp_path, create_clean=True)\n",
    "\n",
    "        umi_count_subset = umi_counts_ad[index_df.index, required_genes]\n",
    "        write_umi_counts(umi_count_subset, tmp_path)\n",
    "\n",
    "        run_txburst_fitting(tmp_path)\n",
    "\n",
    "        txburst_df = collate_txburst_results(tmp_path)\n",
    "\n",
    "        for loc, (column, value) in enumerate(zip(txburst_param_set.index_columns, index_values), start=1):\n",
    "            txburst_df.insert(loc, column, value)\n",
    "\n",
    "        results_df = results_df.append(txburst_df)\n",
    "        results_df = results_df.sort_values(by=sort_columns)\n",
    "        results_df.to_csv(txburst_param_set.results_path, index=False)\n",
    "\n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.ipynb.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
