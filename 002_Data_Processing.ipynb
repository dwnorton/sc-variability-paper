{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads and processes data associated with Hagai *et al.* (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from scipy import linalg, spatial, stats\n",
    "from sklearn import linear_model\n",
    "\n",
    "import rp2\n",
    "from rp2 import create_gene_symbol_map, hagai_2018\n",
    "from rp2.paths import get_output_path\n",
    "\n",
    "rp2.check_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis will be performed on an scRNA dataset generated as part of the study by Hagai *et al.* (2018). UMI counts are available for phagocytes stimulation with lipopolysaccharide (LPS) and dsRNA polyinosinic:polycytidylic acid (poly(I:C) or PIC):\n",
    "\n",
    "> Primary bone marrow-derived mononuclear phagocytes originating from females of four different species (black 6 mouse, brown Norway rat, rabbit and pig)... Cells were stimulated with: (1) ...LPS...or with (2) ...poly(I:C)... LPS stimulation time courses of 0, 2, 4, 6 h were performed for all species. Poly(I:C) stimulations were performed for rodents for 0, 2, 4, 6 h.\n",
    "\n",
    "There are three biological replicates (i.e. three individuals) for each species (as alluded to in the paper and confirmed more explicitly in Supplementary Table 2). In the case of poly(I:C), mouse replicate 1 appears to be missing UMI counts for time 6 h whereas replicate 2 has two readings for this time point (6 and 6A). This does not appear to be discussed in the paper but may suggest that replicate 2 was inadvertently sampled a second time in place of replicate 1. The arrangement of samples is further illustrated in the [table included with the ArrayExpress dataset](https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-6754/samples/). The UMI matrices have been QCed and clustered:\n",
    "\n",
    "> Since bone marrow-derived phagocytes may include secondary cell populations, we focused our analysis on the major cell population. We identified clusters within each data set...and have taken the cells belonging to the largest cluster for further analysis, resulting in a less heterogeneous population of cells.\n",
    "\n",
    "Subsequence analysis will focus upon a subset of the genes:\n",
    "\n",
    "> To quantify transcriptional divergence in immune responses between species, we focused on genes that were differentially expressed during the stimulation (see Methods). For simplicity, we refer to these genes as ‘responsive genes’ (Fig. 1c). In this analysis, we study the subset of these genes with one-to-one orthologues across the studied species. There are 955 such responsive genes in dsRNA-stimulated human fibroblasts and 2,336 in LPS-stimulated mouse phagocytes. \n",
    "\n",
    "# 1. Loading and preparing data<a id=\"1\" />\n",
    "\n",
    "## 1.1. Settings<a id=\"1_1\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_species = \"mouse\"\n",
    "study_replicates = [\"1\", \"2\", \"3\"]\n",
    "study_control = \"unst\"\n",
    "study_treatments = [\"lps\", \"pic\"]\n",
    "study_time_points = [\"0\", \"2\", \"4\", \"6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 1.2. List of \"responsive\" genes<a id=\"1_2\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsive_phagocyte_genes = hagai_2018.load_lps_responsive_genes()\n",
    "print(f\"{len(responsive_phagocyte_genes):,} responsive phagocyte genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a map between gene IDs and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_map = create_gene_symbol_map(study_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. UMI counts<a id=\"1_3\" />\n",
    "\n",
    "Load the UMI counts and reduce the dataset to values of interest (to optimise memory usage and access performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_ad = hagai_2018.load_umi_count(study_species)\n",
    "\n",
    "umi_ad = umi_ad[:, responsive_phagocyte_genes]\n",
    "umi_ad = umi_ad[umi_ad.obs.replicate.isin(study_replicates), :]\n",
    "umi_ad = umi_ad[umi_ad.obs.treatment.isin(study_treatments + [study_control]), :]\n",
    "umi_ad = umi_ad[umi_ad.obs.time_point.isin(study_time_points), :]\n",
    "umi_ad = umi_ad.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a StudyTreatmentSet for each treatment of interest so they may each be analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyTreatmentSet:\n",
    "    @staticmethod\n",
    "    def add_method(method):\n",
    "        setattr(StudyTreatmentSet, method.__name__, method)\n",
    "\n",
    "    def __init__(self, umi_counts_ad, treatments, control_name):\n",
    "        all_treatments = treatments + [control_name]\n",
    "        self.umi_counts_ad = umi_counts_ad[umi_counts_ad.obs.treatment.isin(all_treatments), :]\n",
    "        self.condition_stats_df = None\n",
    "        self.lr_fit_df = None\n",
    "\n",
    "    @property\n",
    "    def number_of_genes(self):\n",
    "        return self.umi_counts_ad.n_vars\n",
    "\n",
    "    @property\n",
    "    def number_of_conditions(self):\n",
    "        return len(self.umi_counts_ad.obs.loc[:, [\"replicate\", \"treatment\", \"time_point\"]].drop_duplicates())\n",
    "\n",
    "    def check_integrity(self):\n",
    "        gene_set = set(self.umi_counts_ad.var_names)\n",
    "        if self.condition_stats_df is not None:\n",
    "            assert(gene_set == set(self.condition_stats_df.gene))\n",
    "\n",
    "    def drop_genes(self, genes):\n",
    "        self.umi_counts_ad = self.umi_counts_ad[:, ~self.umi_counts_ad.var_names.isin(genes)]\n",
    "        self.condition_stats_df = self.condition_stats_df.loc[~self.condition_stats_df.gene.isin(genes)]\n",
    "\n",
    "        self.check_integrity()\n",
    "\n",
    "\n",
    "treatment_sets = {}\n",
    "for treatment in study_treatments:\n",
    "    treatment_sets[treatment] = StudyTreatmentSet(umi_ad, [treatment], study_control)\n",
    "\n",
    "treatment_sets[\"all\"] = StudyTreatmentSet(umi_ad, study_treatments, study_control)\n",
    "\n",
    "for set_name, treatment_set in treatment_sets.items():\n",
    "    print(f'\"{set_name}\" treatment set:')\n",
    "    print(f\"  {treatment_set.number_of_genes} genes\")\n",
    "    print(f\"  {treatment_set.number_of_conditions} conditions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quality control<a id=\"2\" />\n",
    "\n",
    "## 2.1. Settings<a id=\"2_1\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_samples_per_gene = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Remove undersampled genes<a id=\"2_2\" />\n",
    "\n",
    "Calculate per condition statistics (for each treatment set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_condition_stats(self: StudyTreatmentSet):\n",
    "    self.condition_stats_df = hagai_2018.calculate_umi_condition_stats(self.umi_counts_ad)\n",
    "\n",
    "\n",
    "StudyTreatmentSet.add_method(calculate_condition_stats)\n",
    "\n",
    "for treatment_set in treatment_sets.values():\n",
    "    treatment_set.calculate_condition_stats()\n",
    "    display(symbol_map.added_to(treatment_set.condition_stats_df).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop undersampled genes (those that have too few conditions with a non-zero mean UMI count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name, treatment_set in treatment_sets.items():\n",
    "    n_non_zero_means_series = treatment_set.condition_stats_df.groupby(\"gene\", as_index=True)[\"mean\"].apply(np.count_nonzero)\n",
    "    undersampled_genes = n_non_zero_means_series[n_non_zero_means_series < minimum_samples_per_gene].index\n",
    "    treatment_set.drop_genes(undersampled_genes)\n",
    "    print(f'\"{set_name}\" dropped {len(undersampled_genes)} genes ({treatment_set.number_of_genes} remaining)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerate remaining conditions with zero mean UMI count by time point (for each treatment set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sample_points(self: StudyTreatmentSet, condition_ids):\n",
    "    self.condition_stats_df = self.condition_stats_df.drop(index=condition_ids)\n",
    "    self.check_integrity()\n",
    "\n",
    "\n",
    "StudyTreatmentSet.add_method(drop_sample_points)\n",
    "\n",
    "remove_all_zero_mean_samples = True\n",
    "\n",
    "for set_name, treatment_set in treatment_sets.items():\n",
    "    print(f'Zero mean conditions remaining for \"{set_name}\" treatment set:')\n",
    "    zero_mean_series = treatment_set.condition_stats_df.loc[treatment_set.condition_stats_df[\"mean\"] == 0, \"time_point\"]\n",
    "    for time_point, n in zero_mean_series.value_counts().sort_index().iteritems():\n",
    "        print(f\"  {n} at time point {time_point}\")\n",
    "\n",
    "    if remove_all_zero_mean_samples:\n",
    "        treatment_set.drop_sample_points(zero_mean_series.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Remove genes with low abundance<a id=\"2_3\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_max_mean = 1\n",
    "\n",
    "for set_name, treatment_set in treatment_sets.items():\n",
    "    print(f'\"{set_name}\" treatment set:')\n",
    "    max_mean_series = treatment_set.condition_stats_df.groupby(\"gene\")[\"mean\"].apply(np.max).sort_values()\n",
    "\n",
    "    rejected_genes = max_mean_series[max_mean_series < minimum_max_mean]\n",
    "    print(f\"  {len(rejected_genes):,} genes rejected ({len(max_mean_series) - len(rejected_genes):,} remaining)\")\n",
    "\n",
    "    max_mean_series.plot.hist(figsize=(16, 4), bins=40, log=True).set(xlabel=\"Max mean\")\n",
    "    plt.axvline(x=minimum_max_mean)\n",
    "    plt.show()\n",
    "\n",
    "    if len(rejected_genes) == 0:\n",
    "        continue\n",
    "\n",
    "    top_rejected_genes = rejected_genes[-4:]\n",
    "    print(f\"  Top {len(top_rejected_genes)} rejections:\")\n",
    "    _, axes = plt.subplots(1, len(top_rejected_genes), figsize=(4 * len(top_rejected_genes), 4))\n",
    "    for gene_id, ax in zip(top_rejected_genes.index, axes.flatten()):\n",
    "        sns.scatterplot(\n",
    "            x=\"mean\",\n",
    "            y=\"variance\",\n",
    "            hue=\"time_point\",\n",
    "            style=\"replicate\",\n",
    "            data=treatment_set.condition_stats_df.loc[treatment_set.condition_stats_df.gene == gene_id],\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(symbol_map.lookup(gene_id))\n",
    "        ax.set_xlim(0, minimum_max_mean)\n",
    "        ax.set_ylim(0)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    treatment_set.drop_genes(rejected_genes.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Detect outliers<a id=\"2_4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine outliers based on Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mahalanobis_distance(df, column_name=\"distance\"):\n",
    "    centroid = df.mean(axis=0)\n",
    "    cov_mtx = np.cov(df, rowvar=False)\n",
    "    inv_cov_mtx = linalg.inv(cov_mtx)\n",
    "    distances = [spatial.distance.mahalanobis(row, centroid, inv_cov_mtx)\n",
    "                 for row in df.to_numpy()]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        index=df.index,\n",
    "        data={column_name: distances},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers(self: StudyTreatmentSet, distance_threshold):\n",
    "    mahalanobis_distances = self.condition_stats_df.groupby(\"gene\")[[\"mean\", \"variance\"]].apply(calculate_mahalanobis_distance)\n",
    "    self.condition_stats_df[\"m_distance\"] = mahalanobis_distances.loc[self.condition_stats_df.index]\n",
    "    self.condition_stats_df[\"outlier\"] = self.condition_stats_df.m_distance > distance_threshold\n",
    "\n",
    "\n",
    "StudyTreatmentSet.add_method(calculate_outliers)\n",
    "\n",
    "outlier_distance_threshold = np.sqrt(stats.chi2.ppf(0.95, 2))\n",
    "\n",
    "for set_name, treatment_set in treatment_sets.items():\n",
    "    treatment_set.calculate_outliers(outlier_distance_threshold)\n",
    "    n_outliers = np.count_nonzero(treatment_set.condition_stats_df.outlier)\n",
    "    print(f'{n_outliers:,} outliers in \"{set_name}\" treatment set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero(a):\n",
    "    return np.count_nonzero(a == 0)\n",
    "\n",
    "\n",
    "for set_name, treatment_set in treatment_sets.items():\n",
    "    n_non_outlier_series = treatment_set.condition_stats_df.groupby(\"gene\", as_index=True)[\"outlier\"].apply(count_zero).sort_values()\n",
    "    undersampled_genes = n_non_outlier_series[n_non_outlier_series < minimum_samples_per_gene].index\n",
    "    print(f'\"{set_name}\" has {len(undersampled_genes)} undersampled genes if outliers are discounted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mean-variance plots<a id=\"3\" />\n",
    "\n",
    "## 3.1 Fit regression models<a id=\"3_1\" />\n",
    "\n",
    "Fit linear regression model to mean-variance relationship of all genes for all treatment sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_regression(df, lr):\n",
    "    lr_x, lr_y = df.to_numpy().reshape(1, -1, 2).T\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        lr.fit(lr_x, lr_y)\n",
    "\n",
    "    return pd.Series(data={\n",
    "        \"slope\": np.squeeze(lr.coef_),\n",
    "        \"intercept\": np.squeeze(lr.intercept_),\n",
    "        \"r2\": lr.score(lr_x, lr_y),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataframes(df_list, df_ids, id_column_name):\n",
    "    concat_df = pd.concat(\n",
    "        df_list,\n",
    "        keys=df_ids,\n",
    "        names=[id_column_name]\n",
    "    )\n",
    "    return concat_df.reset_index(level=[0]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def calculate_linear_regression_fit(self: StudyTreatmentSet):\n",
    "    if not hasattr(linear_model.RANSACRegressor, \"coef_\"):\n",
    "        setattr(linear_model.RANSACRegressor, \"coef_\", property(lambda self: self.estimator_.coef_))\n",
    "    if not hasattr(linear_model.RANSACRegressor, \"intercept_\"):\n",
    "        setattr(linear_model.RANSACRegressor, \"intercept_\", property(lambda self: self.estimator_.intercept_))\n",
    "\n",
    "    classic_methods = {\n",
    "        \"ols\": linear_model.LinearRegression(fit_intercept=True),\n",
    "        #\"ols_no_intercept\": linear_model.LinearRegression(fit_intercept=False),\n",
    "    }\n",
    "    robust_methods = {\n",
    "        \"huber\": linear_model.HuberRegressor(),\n",
    "        \"ransac\": linear_model.RANSACRegressor(),\n",
    "        \"theil_sen\": linear_model.TheilSenRegressor(),\n",
    "    }\n",
    "    methods_and_views = (\n",
    "        (classic_methods, self.condition_stats_df.loc[~self.condition_stats_df.outlier]),\n",
    "        #(robust_methods, self.condition_stats_df),\n",
    "    )\n",
    "\n",
    "    concat_df_list = []\n",
    "\n",
    "    for methods, method_view in (methods_and_views):\n",
    "        group = method_view.groupby(\"gene\")[[\"mean\", \"variance\"]]\n",
    "\n",
    "        concat_df_list.append(concat_dataframes(\n",
    "            [group.apply(fit_linear_regression, method).reset_index()\n",
    "             for method in methods.values()],\n",
    "            methods.keys(),\n",
    "            \"method\"\n",
    "        ))\n",
    "\n",
    "    self.lr_fit_df = pd.concat(concat_df_list, ignore_index=True)\n",
    "\n",
    "    self.lr_fit_df = self.lr_fit_df.merge(\n",
    "        self.condition_stats_df[~self.condition_stats_df.outlier].groupby(\"gene\").agg({\"min\": \"min\", \"max\": max}).rename(\n",
    "            columns={\"min\": \"min_mean\", \"max\": \"max_mean\"}\n",
    "        ),\n",
    "        left_on=\"gene\",\n",
    "        right_index=True,\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    self.lr_fit_df = self.lr_fit_df.loc[:, [\"gene\", \"method\", \"slope\", \"intercept\", \"r2\", \"min_mean\", \"max_mean\"]].sort_values(by=[\"gene\", \"method\"])\n",
    "\n",
    "\n",
    "StudyTreatmentSet.add_method(calculate_linear_regression_fit)\n",
    "\n",
    "for treatment_set in treatment_sets.values():\n",
    "    treatment_set.calculate_linear_regression_fit()\n",
    "\n",
    "r2_plot_df = concat_dataframes(\n",
    "    [ts.lr_fit_df for ts in treatment_sets.values()],\n",
    "    treatment_sets.keys(),\n",
    "    \"set\"\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"set\",\n",
    "    y=\"r2\",\n",
    "    hue=\"method\",\n",
    "    data=r2_plot_df,\n",
    ")\n",
    "plt.ylim(bottom=0.6)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save results<a id=\"3_2\" />\n",
    "\n",
    "Save the descriptive statistics and results of fitting the regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(self: StudyTreatmentSet, output_path, prefix, symbol_map):\n",
    "    symbol_map.added_to(self.condition_stats_df).to_csv(output_path.joinpath(prefix + \"_stats_per_condition_per_gene.csv\"), index=False)\n",
    "    symbol_map.added_to(self.lr_fit_df).to_csv(output_path.joinpath(prefix + \"_lr_fit_per_gene.csv\"), index=False)\n",
    "\n",
    "\n",
    "StudyTreatmentSet.add_method(save_data)\n",
    "\n",
    "output_path = get_output_path()\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for treatment, treatment_set in treatment_sets.items():\n",
    "    file_prefix = f\"{study_species}_{treatment}\"\n",
    "    treatment_set.save_data(output_path, file_prefix, symbol_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Display plots<a id=\"3_3\" />\n",
    "\n",
    "Show mean-variance plots for 10 most variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes = set.intersection(*[set(treatment_set.umi_counts_ad.var_names)\n",
    "                                  for treatment_set in treatment_sets.values()])\n",
    "print(f\"{len(common_genes):,} genes common to all treatment sets\")\n",
    "\n",
    "get_output_path(f\"{study_species}_common_treatment_set_genes.txt\").write_text(\"\\n\".join(common_genes))\n",
    "\n",
    "# Determine genes with top R2 scores\n",
    "plot_lr_df = treatment_sets[\"lps\"].lr_fit_df\n",
    "plot_lr_df = plot_lr_df.loc[plot_lr_df.method == \"ols\"].set_index(\"gene\").loc[common_genes]\n",
    "top_r2_genes = plot_lr_df.r2.sort_values(ascending=False)\n",
    "\n",
    "points_treatment_set = treatment_sets[\"all\"]\n",
    "\n",
    "plot_gene_ids = top_r2_genes.index[:25]\n",
    "\n",
    "for gene_idx, gene_id in enumerate(plot_gene_ids):\n",
    "    gene_df = points_treatment_set.condition_stats_df.loc[points_treatment_set.condition_stats_df.gene == gene_id]\n",
    "\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=gene_df,\n",
    "        x=\"mean\",\n",
    "        y=\"variance\",\n",
    "        hue=\"treatment\",\n",
    "        style=\"replicate\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    line_df = []\n",
    "    lr_plot_x = np.asarray([0, gene_df[\"mean\"].max()])\n",
    "\n",
    "    for set_name, treatment_set in treatment_sets.items():\n",
    "        lr_fit_df = treatment_set.lr_fit_df.loc[treatment_set.lr_fit_df.gene == gene_id]\n",
    "\n",
    "        for lr_method, lr_method_df in lr_fit_df.groupby(\"method\"):\n",
    "            slope, intercept = lr_method_df[[\"slope\", \"intercept\"]].squeeze()\n",
    "\n",
    "            line_df.append(pd.DataFrame(data={\n",
    "                \"set\": set_name,\n",
    "                \"method\": lr_method,\n",
    "                \"mean\": lr_plot_x,\n",
    "                \"variance\": (lr_plot_x * slope) + intercept,\n",
    "            }))\n",
    "\n",
    "    line_df = pd.concat(line_df, ignore_index=True)\n",
    "    line_style = \"method\" if line_df.method.nunique() > 1 else None\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=\"mean\",\n",
    "        y=\"variance\",\n",
    "        data=line_df,\n",
    "        hue=\"set\",\n",
    "        style=line_style,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"{gene_idx + 1}. {symbol_map.lookup(gene_id)} ({gene_id})\")\n",
    "    plt.xlabel(\"Mean\")\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,.ipynb.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
