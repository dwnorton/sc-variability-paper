{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from IPython.display import display\n",
    "\n",
    "import rp2.data\n",
    "from rp2 import hagai_2018\n",
    "\n",
    "rp2.check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_columns = [\"replicate\", \"treatment\", \"time_point\"]\n",
    "time_points = [\"0\", \"2\", \"4\", \"6\"]\n",
    "\n",
    "gene_info_df = rp2.load_biomart_gene_symbols_df(\"mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_umi_adata = hagai_2018.load_umi_counts(\"mouse\")\n",
    "mouse_umi_adata = mouse_umi_adata[mouse_umi_adata.obs.time_point.isin(time_points)].copy()\n",
    "\n",
    "print(\"Full Hagai mouse dataset has:\")\n",
    "print(f\"  {mouse_umi_adata.n_obs:,} cells\")\n",
    "print(f\"  {mouse_umi_adata.n_vars:,} genes\")\n",
    "\n",
    "assert(mouse_umi_adata.n_obs == 53_086)\n",
    "assert(mouse_umi_adata.n_vars == 22_048)\n",
    "\n",
    "del mouse_umi_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_counts_adata = hagai_2018.load_counts(\"mouse\", scaling=\"median\")\n",
    "mouse_counts_adata = mouse_counts_adata[mouse_counts_adata.obs.time_point.isin(time_points)].copy()\n",
    "\n",
    "print(\"Scaled Hagai mouse dataset has:\")\n",
    "print(f\"  {mouse_counts_adata.n_vars:,} genes\")\n",
    "\n",
    "assert(mouse_counts_adata.n_obs == 53_086)\n",
    "assert(mouse_counts_adata.n_vars == 16_798)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps_responsive_gene_ids = mouse_counts_adata.var.index[mouse_counts_adata.var.lps_responsive]\n",
    "print(f\"{len(lps_responsive_gene_ids):,} genes are LPS-responsive\")\n",
    "\n",
    "assert(len(lps_responsive_gene_ids) == 2_336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_gene_symbols = [\"Tnf\"]\n",
    "additional_gene_ids = gene_info_df.index[gene_info_df.symbol.isin(additional_gene_symbols)]\n",
    "analysis_gene_ids = sorted(set(lps_responsive_gene_ids).union(additional_gene_ids))\n",
    "\n",
    "print(f\"{len(analysis_gene_ids):,} genes to be used in analysis\")\n",
    "\n",
    "assert(len(analysis_gene_ids) == 2_337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df = mouse_counts_adata.obs[condition_columns].drop_duplicates()\n",
    "\n",
    "print(f\"{len(condition_df)} conditions per gene\")\n",
    "print(f\"{len(condition_df) * len(analysis_gene_ids)} conditions overall\")\n",
    "\n",
    "display(condition_df.replicate.value_counts().sort_index())\n",
    "\n",
    "assert(len(condition_df) == 20)\n",
    "assert((20 * 2_337) == 46_740)\n",
    "\n",
    "del condition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_count_adata = mouse_counts_adata[:, analysis_gene_ids].copy()\n",
    "gene_condition_stats_df = hagai_2018.calculate_counts_condition_stats(analysis_count_adata)\n",
    "\n",
    "assert(len(gene_condition_stats_df) == 46_740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mean_variance_trends(df):\n",
    "    x = sm.add_constant(df[\"mean\"])\n",
    "    y = df[\"variance\"]\n",
    "    rlm_results = sm.RLM(y, x, M=sm.robust.norms.HuberT(t=1.345)).fit()\n",
    "\n",
    "    results = {\n",
    "        \"intercept\": rlm_results.params[0],\n",
    "        \"slope\": rlm_results.params[1],\n",
    "        \"intercept_pval\": rlm_results.pvalues[0],\n",
    "        \"slope_pval\": rlm_results.pvalues[1],\n",
    "        \"r2_unweighted\": metrics.r2_score(y, rlm_results.fittedvalues),\n",
    "        \"r2_weighted\": metrics.r2_score(y, rlm_results.fittedvalues, sample_weight=rlm_results.weights),\n",
    "    }\n",
    "    return pd.Series(results)\n",
    "\n",
    "\n",
    "treatment_sets = {\n",
    "    \"all\": [\"unst\", \"lps\", \"pic\"],\n",
    "#    \"lps\": [\"unst\", \"lps\"],\n",
    "#    \"pic\": [\"unst\", \"pic\"],\n",
    "}\n",
    "\n",
    "mv_fit_map = {set_name: gene_condition_stats_df[gene_condition_stats_df.treatment.isin(set_list)].groupby(\"gene\").apply(fit_mean_variance_trends)\n",
    "              for set_name, set_list in treatment_sets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_treatment_mv_fit = mv_fit_map[\"all\"].copy()\n",
    "all_treatment_mv_fit[\"accept_intercept\"] = all_treatment_mv_fit[\"intercept_pval\"] < 0.05\n",
    "all_treatment_mv_fit[\"accept_slope\"] = all_treatment_mv_fit[\"slope_pval\"] < 0.05\n",
    "all_treatment_mv_fit[\"accept_fit\"] = all_treatment_mv_fit[\"accept_intercept\"] & all_treatment_mv_fit[\"accept_slope\"]\n",
    "all_treatment_mv_fit[\"accept_r2\"] = all_treatment_mv_fit[\"r2_unweighted\"] > 0.6\n",
    "display(all_treatment_mv_fit[[c for c in all_treatment_mv_fit.columns if c.startswith(\"accept_\")]].agg(np.count_nonzero))\n",
    "\n",
    "print(f\"{np.count_nonzero(all_treatment_mv_fit.accept_fit):,} mean-variance trends are significant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_treatment_good_mv_fit = all_treatment_mv_fit.loc[all_treatment_mv_fit.accept_fit & all_treatment_mv_fit.accept_r2]\n",
    "\n",
    "print(f\"{len(all_treatment_good_mv_fit):,} mean-variance trends have a good fit (based on unweighted R2)\")\n",
    "print(f\"i.e. {100 * (len(all_treatment_good_mv_fit) / len(analysis_gene_ids)):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txburst_df = rp2.data.load_txburst_results(\"mouse\", condition_columns, \"median\")\n",
    "txburst_df = txburst_df.loc[txburst_df.time_point.isin(time_points)].copy()\n",
    "\n",
    "assert(len(txburst_df) == 46_740)\n",
    "assert(len(txburst_df[condition_columns].drop_duplicates()) == 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txburst_df[\"valid_points\"] = txburst_df.bs_point.notna() & txburst_df.bf_point.notna()\n",
    "txburst_df[\"valid_bs_interval\"] = txburst_df.bs_lower.notna() & txburst_df.bs_upper.notna()\n",
    "txburst_df[\"valid_bf_interval\"] = txburst_df.bf_lower.notna() & txburst_df.bf_upper.notna()\n",
    "txburst_df[\"valid_intervals\"] = txburst_df.valid_bs_interval & txburst_df.valid_bf_interval\n",
    "display(txburst_df[[\"keep\"] + [c for c in txburst_df.columns if c.startswith(\"valid_\")]].agg(np.count_nonzero))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.ipynb.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
